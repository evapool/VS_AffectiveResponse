---
title: "REWOD_HEDO_RM"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R code for FOR REWOD_HED
# last modified on Nov 2018 by David
#SETUP

```{r, preliminary stuff, echo=TRUE, include=FALSE}
# load libraries
library(lme4)
library(lmerTest)
library(ggplot2)
library(dplyr)
library(plyr)
```
```{r}
# Set working directory
analysis_path <- '~/rewod/DATABASES/'# for this to work the script needs to be sourced
setwd(analysis_path)

# open dataset (session two only)
REWOD_HED <- read.delim(file.path(analysis_path,'REWOD_HEDONIC_ses_second.txt'), header = T, sep ='') # read in dataset

# define factors
REWOD_HED$id               <- factor(REWOD_HED$id)
#REWOD_HED$trial            <- factor(REWOD_HED$trial)
REWOD_HED$session          <- factor(REWOD_HED$session)
REWOD_HED$condition        <- factor(REWOD_HED$condition)

## remove sub 1 & 8 
REWOD_HED <- filter(REWOD_HED, id != "1" & id != "8")
```
# PLOTS

##plot (non-averaged per participant) 
```{r boxplots , fig.align = "center"}
# liking boxplot by condition
boxplot(REWOD_HED$perceived_liking ~ REWOD_HED$condition, las = 1)

# liking boxplot by time
boxplot(REWOD_HED$perceived_liking ~ REWOD_HED$trial, las = 1)

# intensity boxplot by condition
boxplot(REWOD_HED$perceived_intensity ~ REWOD_HED$condition, las = 1)

# intensity boxplot by time
boxplot(REWOD_HED$perceived_intensity ~ REWOD_HED$trial, las = 1)

# get means by condition 
bt = ddply(REWOD_HED, .(trial), summarise,  perceived_liking = mean(perceived_liking, na.rm = TRUE), perceived_intensity = mean(perceived_intensity, na.rm = TRUE)) 
# get means by condition and trial
bct = ddply(REWOD_HED, .(condition, trial), summarise,  perceived_liking = mean(perceived_liking, na.rm = TRUE), perceived_intensity = mean(perceived_intensity, na.rm = TRUE)) 

# get means by participant 
bs = ddply(REWOD_HED, .(id, trial), summarise, perceived_liking = mean(perceived_liking, na.rm = TRUE), perceived_intensity = mean(perceived_intensity, na.rm = TRUE))
```

## plot overall effect Liking
```{r boxplots overall effect Liking, fig.align = "center"}

# perceived_liking average per trial and id
boxplot(bs$perceived_liking ~ bs$trial, las = 1)


#plot perceived_liking to see the trajectory of learning ((overall average by trials)
ggplot(bt, aes(x = trial, y = perceived_liking, fill = I('royalblue1'), color = I('royalblue4'))) +
  geom_point() + geom_line(group=1) +
  guides(color = "none", fill = "none") +
  guides(color = "none", fill = "none") +
  theme_bw() +
  labs(
    title = "Liking By Time",
    x = "Trial",
    y = "perceived_liking"
  )

#OR different representation
ggplotRegression <- function (fit) {
  
  ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) + 
    geom_point() +
    stat_smooth(method = "lm", col = "red") +
    labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
                       "Intercept =",signif(fit$coef[[1]],5 ),
                       " Slope =",signif(fit$coef[[2]], 5),
                       " P =",signif(summary(fit)$coef[2,4], 5)))
}

# plot perceived_likings by time with regression lign
ggplotRegression(lm(perceived_liking ~ trial, data = bt))

#plot liking to see the trajectory of learning (by condition) 
ggplot(bct, aes(x = trial, y = perceived_liking, color = condition)) +
  geom_point() +
  geom_line(aes(group = condition), alpha = .3, size = 1) +
  scale_colour_manual("", 
                      values = c("chocolate"="green", "empty"="red", "neutral"="blue")) +
  theme_bw() +
  labs(
    title = "Liking By Time By condition",
    x = "Trial",
    y = "perceived_liking"
  )

# plot liking by time by condition with regression lign
ggplotRegression(lm(perceived_liking ~ trial*condition, data = bct)) + 
  facet_wrap(~condition)


```

## plot overall effect Intensity
```{r boxplots overall effect Intensity, fig.align = "center"}
# perceived_intensity average per trial and id
boxplot(bs$perceived_intensity ~ bs$trial, las = 1)

#plot perceived_intensity to see the trajectory of learning ((overall average by trials)
ggplot(bt, aes(x = trial, y = perceived_intensity, fill = I('royalblue1'), color = I('royalblue4'))) +
  geom_point() + geom_line(group=1) +
  guides(color = "none", fill = "none") +
  guides(color = "none", fill = "none") +
  theme_bw() +
  labs(
    title = "intensity By Time",
    x = "Trial",
    y = "perceived_intensity"
  )

# plot perceived_likings by time with regression lign
ggplotRegression(lm(perceived_intensity ~ trial, data = bt))

#plot intensity to see the trajectory of learning (by condition) 
ggplot(bct, aes(x = trial, y = perceived_intensity, color = condition)) +
  geom_point() +
  geom_line(aes(group = condition), alpha = .3, size = 1) +
  scale_colour_manual("", 
                      values = c("chocolate"="green", "empty"="red", "neutral"="blue")) +
  theme_bw() +
  labs(
    title = "intensity By Time By condition",
    x = "Trial",
    y = "perceived_intensity"
  )

# plot liking by time by condition with regression lign
ggplotRegression(lm(perceived_intensity ~ trial*condition, data = bct)) + 
  facet_wrap(~condition)
```


# ANALYSIS
##contrasts
```{r}
REWOD_HED$cvalue[REWOD_HED$condition== 'chocolate']     <- 2
REWOD_HED$cvalue[REWOD_HED$condition== 'empty']     <- -1
REWOD_HED$cvalue[REWOD_HED$condition== 'neutral']     <- -1
REWOD_HED$cvalue       <- factor(REWOD_HED$cvalue)
```

##1. Liking: do participants prefer to the reward (chocolate) condition? 
```{r}
# lmer analyis ~ cvalue 
main.liking = lmer(perceived_liking ~ cvalue + (1+cvalue|id) + (1|trial), data = REWOD_HED, REML = FALSE)
anova(main.liking)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_liking ~ cvalue + Error(id / (cvalue)), data = REWOD_HED))

# model comparison
main.liking.0 = lmer(perceived_liking ~ (1|id) + (1|trial), data = REWOD_HED, REML = FALSE)
anova(main.liking.0, main.liking, test = 'Chisq')
#sentence => main.liking is signifincatly better than the null model

# lmer analyis cvalue and trial 
main.liking.1 = lmer(perceived_liking ~ cvalue + trial + (1+cvalue|id) + (1|trial), data = REWOD_HED, REML = FALSE)
anova(main.liking.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_liking ~ cvalue + trial + Error(id / (cvalue)), data = REWOD_HED))

# model comparison
anova(main.liking, main.liking.1, test = 'Chisq')
#sentence => main.liking1 is signifincatly better than main.liking (adding trial makes the model predict better)

# lmer analyis (+interaction) # should I have used the condition*trial variable instead?
main.liking.2 = lmer(perceived_liking ~ cvalue*trial + (1+cvalue|id) + (1|trial), data = REWOD_HED, REML = FALSE)#  # second 1+ would need to be condition*trial or not?
anova(main.liking.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_liking ~ cvalue*trial + Error(id / (cvalue)), data = REWOD_HED))

# model comparison
anova(main.liking.1, main.liking.2, test = 'Chisq')
#sentence => main.liking2 is signifincatly better than main.liking1 (adding interaction helps the model predict better)
```

## 2. Intensity: do participants find the reward (chocolate) condition more intense?

```{r}
# factorise trial
REWOD_HED$trial            <- factor(REWOD_HED$trial)

# lmer analyis ~ condition 
main.intensity = lmer(perceived_intensity ~ cvalue + (1+cvalue|id) + (1|trial), data = REWOD_HED, REML = FALSE)
anova(main.intensity)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_intensity ~ cvalue + Error(id / (cvalue)), data = REWOD_HED))

# model comparison
main.intensity.0 = lmer(perceived_intensity ~ (1|id) + (1|trial), data = REWOD_HED, REML = FALSE)
anova(main.intensity.0, main.intensity, test = 'Chisq')
#sentence => main.liking is signifincatly better than the null model

# lmer analyis condition and trial 
main.intensity.1 = lmer(perceived_intensity ~ cvalue + trial + (1+cvalue|id) + (1|trial), data = REWOD_HED, REML = FALSE)
anova(main.intensity.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_intensity ~ cvalue + trial + Error(id / (cvalue)), data = REWOD_HED))

# model comparison
anova(main.intensity, main.intensity.1, test = 'Chisq')
#sentence => main.liking1 is signifincatly better than main.liking (adding trial makes the model predict better)

# lmer analyis (+interaction) # should I have used the condition*trial variable instead?
main.intensity.2 = lmer(perceived_intensity ~ cvalue*trial + (1+cvalue|id) + (1|trial), data = REWOD_HED, REML = FALSE)#  # second 1+ would need to be cvalue*trial or not?
anova(main.intensity.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_intensity ~ cvalue*trial + Error(id / (cvalue)), data = REWOD_HED))

# model comparison
anova(main.intensity.1, main.intensity.2, test = 'Chisq')
#sentence => HOWEVER here main.liking2 is NOT signifincatly better than main.liking1 (adding interaction DOESNT help the model predict better)
```


## 3. Specific test without empty  
```{r}
#removing empty condition
REWOD_HED.woemp <- filter(REWOD_HED, cvalue != "empty")

#contrasts
REWOD_HED.woemp$cvalue[REWOD_HED.woemp$condition== 'chocolate']     <- 2
REWOD_HED.woemp$cvalue[REWOD_HED.woemp$condition== 'empty']     <- -1
REWOD_HED.woemp$cvalue[REWOD_HED.woemp$condition== 'neutral']     <- -1
REWOD_HED.woemp$cvalue       <- factor(REWOD_HED.woemp$cvalue)
```

## 3.1. Liking: do participants prefer to the reward (chocolate) condition? 
```{r}
# lmer analyis ~ condition 
main.liking = lmer(perceived_liking ~ cvalue + (1+cvalue|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)
anova(main.liking)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_liking ~ cvalue + Error(id / (cvalue)), data = REWOD_HED.woemp))

# model comparison
main.liking.0 = lmer(perceived_liking ~ (1|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)
anova(main.liking.0, main.liking, test = 'Chisq')
#sentence => main.liking is signifincatly better than the null model

# lmer analyis condition and trial 
main.liking.1 = lmer(perceived_liking ~ cvalue + trial + (1+cvalue|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)
anova(main.liking.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_liking ~ cvalue + trial + Error(id / (cvalue)), data = REWOD_HED.woemp))

# model comparison
anova(main.liking, main.liking.1, test = 'Chisq')
#sentence => main.liking1 is signifincatly better than main.liking (adding trial makes the model predict better)

# lmer analyis (+interaction) # should I have used the condition*trial variable instead?
main.liking.2 = lmer(perceived_liking ~ cvalue*trial + (1+cvalue|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)#  # second 1+ would need to be condition*trial or not?
anova(main.liking.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_liking ~ cvalue*trial + Error(id / (cvalue)), data = REWOD_HED.woemp))

# model comparison
anova(main.liking.1, main.liking.2, test = 'Chisq')
#sentence => main.liking2 is signifincatly better than main.liking1 (adding interaction helps the model predict better)
```

## 3.2. Intensity: do participants find the reward (chocolate) condition more intense? 

```{r}
# lmer analyis ~ condition 
main.intensity = lmer(perceived_intensity ~ cvalue + (1+cvalue|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)
anova(main.intensity)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_intensity ~ cvalue + Error(id / (cvalue)), data = REWOD_HED.woemp))

# model comparison
main.intensity.0 = lmer(perceived_intensity ~ (1|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)
anova(main.intensity.0, main.intensity, test = 'Chisq')
#sentence => main.liking1 is signifincatly better than the null model

# lmer analyis condition and trial 
main.intensity.1 = lmer(perceived_intensity ~ cvalue + trial + (1+cvalue|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)
anova(main.intensity.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_intensity ~ cvalue + trial + Error(id / (cvalue)), data = REWOD_HED.woemp))

# model comparison
anova(main.intensity, main.intensity.1, test = 'Chisq')
#sentence => main.liking1 is signifincatly better than main.liking (adding trial makes the model predict better)

# lmer analyis (+interaction) # should I have used the condition*trial variable instead?
main.intensity.2 = lmer(perceived_intensity ~ cvalue*trial + (1+cvalue|id) + (1|trial), data = REWOD_HED.woemp, REML = FALSE)#  # second 1+ would need to be condition*trial or not?
anova(main.intensity.1)

# quick check with classical anova (! this is not reliable)
summary(aov(perceived_intensity ~ cvalue*trial + Error(id / (cvalue)), data = REWOD_HED.woemp))

# model comparison
anova(main.intensity.1, main.intensity.2, test = 'Chisq')
#sentence => HOWEVER here main.liking2 is NOT signifincatly better than main.liking1 (adding interaction DOESNT help the model predict better)
```

